{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab_WorkingVersion.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/40love/licenta2019/blob/master/Colab_WorkingVersion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfTAPhyYuZbh",
        "colab_type": "text"
      },
      "source": [
        "# Fisier Antrenament"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKFfAfRdwanF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run once to import to files your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqUyknG0PxIJ",
        "colab_type": "code",
        "outputId": "d9dad173-3cc8-4ecf-df9b-afc52558067c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "'''MAININPUT\n",
        "Created on Apr 24, 2019\n",
        "\n",
        "@author: PITA\n",
        "'''\n",
        "#from Package import GetInput, Retea \n",
        "import numpy\n",
        "limita = 0.5\n",
        "def tipareste(x):\n",
        "    lst=[]\n",
        "    for it in range(len(x)):\n",
        "        for jt in range(len(x[it])):\n",
        "          if x[it][jt] not in lst:\n",
        "              lst.append(x[it][jt])\n",
        "    lst.sort(reverse=True)\n",
        "    print(lst)  \n",
        "    return lst\n",
        "def analizeazaPoza(poza):\n",
        "    import cv2\n",
        "    pixeli = GetInput.prelucreazaImagineInputAux(poza)\n",
        "    image = cv2.imread(poza)\n",
        "    model = Retea.getModel()\n",
        "    pred = model.predict(numpy.array([pixeli]))\n",
        "    suma = 0\n",
        "    cnt = 0\n",
        "    for it in range(len(pred[0])):\n",
        "        \n",
        "        for jt in range(len(pred[0][it])):\n",
        "            \n",
        "            if pred[0][it][jt]>limita:\n",
        "                suma +=pred[0][it][jt]\n",
        "                cnt +=1\n",
        "    medie = (float(suma)/float(cnt))\n",
        "    for it in range(len(pred[0])):\n",
        "        for jt in range(len(pred[0][it])):\n",
        "            if pred[0][it][jt]>medie:    \n",
        "                cv2.circle(image,(it,jt), 3, (0,0,255), -1)\n",
        "    #tipareste(pred)\n",
        "    cv2.imshow(\"IataCarii\", image)\n",
        "    cv2.waitKey(0)\n",
        "    print(medie)\n",
        "    print(pred.shape)\n",
        "    print(pred)\n",
        "    \n",
        "    \n",
        "def analizeazaPozaDebug(poza):\n",
        "    import cv2\n",
        "    from keras.models import model_from_json\n",
        "    #model = Antrenament.incarcaModel()\n",
        "    json_file = open('model.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    loaded_model.load_weights(\"model.h5\")\n",
        "    print(\"Loaded model from disk\")\n",
        "    model = loaded_model\n",
        "    pixeli = GetInput.prelucreazaImagineInputAux(poza)\n",
        "    image = cv2.imread(poza)\n",
        "    \n",
        "    pred = model.predict(numpy.array([pixeli]))\n",
        "    suma = 0\n",
        "    cnt = 0\n",
        "    for it in range(len(pred[0])):\n",
        "        \n",
        "        for jt in range(len(pred[0][it])):\n",
        "            \n",
        "            if pred[0][it][jt]>limita:\n",
        "                suma +=pred[0][it][jt]\n",
        "                cnt +=1\n",
        "    medie = (float(suma)/float(cnt))\n",
        "    #medie = 5000000\n",
        "    for it in range(len(pred[0])):\n",
        "        for jt in range(len(pred[0][it])):\n",
        "            if pred[0][it][jt]>medie:    \n",
        "                #cv2.circle(image,(it*4,jt*4), 3, (0,0,255), -1)\n",
        "                pass\n",
        "    lst = tipareste(pred[0])\n",
        "    for kt in lst :\n",
        "        for it in range(len(pred[0])):\n",
        "            for jt in range(len(pred[0][it])):\n",
        "                if pred[0][it][jt]==kt:    \n",
        "                    cv2.circle(image,(it,jt), 3, (0,0,255), -1)\n",
        "                    cv2.imshow(\"IataCarii\", image)\n",
        "                    cv2.waitKey(0)\n",
        "                    \n",
        "    #cv2.imshow(\"IataCarii\", image)\n",
        "    cv2.waitKey(0)\n",
        "    print(medie)\n",
        "    print(pred.shape)\n",
        "    print(pred)\n",
        "    \n",
        "'''GetInput\n",
        "Created on Apr 24, 2019\n",
        "@author: PITA\n",
        "'''\n",
        "from PIL import Image\n",
        "import numpy\n",
        "import os\n",
        "from builtins import isinstance\n",
        "\n",
        "directorImaginiInput=\"/content/drive/My Drive/Colab Notebooks/licenta2019/Radiografii_DB\"\n",
        "directorImaginiOutput=\"/content/drive/My Drive/Colab Notebooks/licenta2019/Radiografii_DB_Output\"\n",
        "dimensiune = (256,256)\n",
        "dimensiuneOut = (256,256)\n",
        "factorZoom = dimensiune[0]/dimensiuneOut[0]\n",
        "def tranformaImagine(imagine):\n",
        "    imagine=Image.open(imagine).convert('L')\n",
        "    #image = color.rgb2gray(imagine)\n",
        "    image_resized = imagine.resize(dimensiune,Image.ANTIALIAS)\n",
        "    pixels = list(image_resized.getdata())\n",
        "    width, height = image_resized.size\n",
        "    pixels = [pixels[i * width:(i + 1) * width] for i in range(height)]\n",
        "    return pixels\n",
        "\n",
        "def getPixeliOutput(fisier):\n",
        "    output = []\n",
        "    # import the necessary packages\n",
        "    import imutils\n",
        "    import cv2\n",
        "    \n",
        "\n",
        "    # load the image, convert it to grayscale, blur it slightly,\n",
        "    # and threshold it\n",
        "    image = cv2.imread(fisier)\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    lower_red = numpy.array([0,100,100])\n",
        "    upper_red = numpy.array([179, 255, 255])\n",
        "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
        "    #cv2.imshow(\"HSV\", hsv)\n",
        "   # cv2.waitKey(0)\n",
        "   # cv2.imshow(\"Mask\", mask)\n",
        "   # cv2.waitKey(0)\n",
        "    \n",
        "    blurred = cv2.GaussianBlur(mask, (5, 5), 0)\n",
        "    thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY)[1]\n",
        "    # find contours in the thresholded image\n",
        "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "    # Create a black image\n",
        "    img = numpy.zeros((600,600,3), numpy.uint8)\n",
        "    for c in cnts:\n",
        "        # compute the center of the contour\n",
        "        M = cv2.moments(c)\n",
        "        print(M[\"m10\"])\n",
        "        print(M[\"m00\"])\n",
        "        print(M[\"m01\"])\n",
        "        if M[\"m00\"] != 0.0 :\n",
        "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cY = int(M[\"m01\"] / M[\"m00\"])   \n",
        "            output.append([cX,cY])\n",
        "            cv2.circle(img,(cX,cY), 3, (0,0,255), -1)\n",
        "    \n",
        "    print(fisier)  \n",
        "    print(output)\n",
        "    #cv2.imshow(\"Mask\", img)\n",
        "    #cv2.waitKey(0)\n",
        "    return output\n",
        "\n",
        "def prelucreazaImagineOutputAux(fisier):\n",
        "    numeComplet = os.path.join(directorImaginiOutput,fisier)\n",
        "    pixeliOutput = getPixeliOutput(numeComplet)\n",
        "    cheieDictionar = fisier.split(\".\")[0]\n",
        "    if cheieDictionar not in dictionarImagini:\n",
        "        dictionarImagini[cheieDictionar]=[0,0]\n",
        "    y_t = []\n",
        "    y = [-1]*dimensiuneOut[0]\n",
        "    for _ in range(dimensiuneOut[1]):\n",
        "        y_t.append(y)\n",
        "    for pixel in pixeliOutput:\n",
        "        for kt in range(int(pixel[0]/factorZoom)-1,int(pixel[0]/factorZoom)+2):\n",
        "            for lt in range(int(pixel[1]/factorZoom)-1,int(pixel[1]/factorZoom)+2):\n",
        "                y_t[pixel[0]][pixel[1]] = 1\n",
        "        #y_t[int(pixel[0]/factorZoom)][int(pixel[1]/factorZoom)] = 1\n",
        "    #y_t = numpy.reshape(y_t,(dimensiune[0],dimensiune[1],1))\n",
        "    dictionarImagini[cheieDictionar][1]=y_t\n",
        "    return y_t\n",
        "\n",
        "def prelucreazaImagineOutput(fisier):\n",
        "    fisierMirror = mirrorImage(fisier,directorImaginiOutput)\n",
        "    \n",
        "    prelucreazaImagineOutputAux(fisier)\n",
        "    prelucreazaImagineOutputAux(fisierMirror)\n",
        "    \n",
        "def prelucreazaImagineInputAux(fisier):\n",
        "    numeComplet = os.path.join(directorImaginiInput,fisier)\n",
        "    img = tranformaImagine(numeComplet)\n",
        "    img=numpy.reshape(img,(dimensiune[0],dimensiune[1],1))\n",
        "    if fisier.split(\".\")[0] not in dictionarImagini:\n",
        "        dictionarImagini[fisier.split(\".\")[0]] = [0,0]\n",
        "    \n",
        "    dictionarImagini[fisier.split(\".\")[0]][0]=img\n",
        "    return img\n",
        "    \n",
        "    \n",
        "def mirrorImage(fisier,director):\n",
        "    numeComplet = os.path.join(director,fisier)\n",
        "    image_obj = Image.open(numeComplet)\n",
        "    rotated_image = image_obj.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    fisierMirror = fisier.split(\".\")[0]+\"mirror.\"+fisier.split(\".\")[1]\n",
        "    numeCompletMirror = os.path.join(director,fisierMirror)\n",
        "    rotated_image.save(numeCompletMirror)\n",
        "    return fisierMirror\n",
        "\n",
        "def prelucreazaImagineInput(fisier):\n",
        "    fisierMirror = mirrorImage(fisier,directorImaginiInput)\n",
        "    prelucreazaImagineInputAux(fisier)\n",
        "    prelucreazaImagineInputAux(fisierMirror)\n",
        "\n",
        "dictionarImagini={}  #dictionar[NumeImagine] = [intrarePiexeli,iesirePixelCarii]\n",
        "\n",
        "def resizePoza(directorImagini,fisier,dimensiuneA):\n",
        "    '''\n",
        "    numeComplet = os.path.join(directorImagini,fisier)\n",
        "    imagine=Image.open(numeComplet)#.convert('L')\n",
        "    image_resized = imagine.resize(dimensiuneA,Image.ANTIALIAS)\n",
        "    numeOutput = fisier.split(\".\")[0] + \"aux\"+\".\"+fisier.split(\".\")[1]\n",
        "    numeComplet = os.path.join(directorImagini,numeOutput)\n",
        "    image_resized.save(numeComplet)\n",
        "    return numeOutput\n",
        "    '''\n",
        "    import cv2\n",
        "\n",
        "    desired_size = dimensiuneA[0]\n",
        "    im_pth = os.path.join(directorImagini,fisier)\n",
        "\n",
        "    im = cv2.imread(im_pth)\n",
        "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
        "\n",
        "    ratio = float(desired_size)/max(old_size)\n",
        "    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "\n",
        "    # new_size should be in (width, height) format\n",
        "\n",
        "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
        "\n",
        "    delta_w = desired_size - new_size[1]\n",
        "    delta_h = desired_size - new_size[0]\n",
        "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "\n",
        "    color = [0, 0, 0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "        value=color)\n",
        "    numeOutput = fisier.split(\".\")[0] + \"aux\"+\".\"+fisier.split(\".\")[1]\n",
        "    numeComplet = os.path.join(directorImagini,numeOutput)\n",
        "    cv2.imwrite(numeComplet, new_im)\n",
        "    return numeOutput\n",
        "def mainInput():\n",
        "    from os import listdir\n",
        "    from os.path import isfile, join\n",
        "    onlyfiles = [f for f in listdir(directorImaginiInput) if isfile(join(directorImaginiInput, f))]\n",
        "    for fisier in onlyfiles:\n",
        "        if (fisier.endswith(\"jpg\") or fisier.endswith(\"png\") ) and \"aux\" not in fisier:\n",
        "            fisier = resizePoza(directorImaginiInput,fisier,dimensiune)\n",
        "            prelucreazaImagineInput(fisier)\n",
        "            \n",
        "    onlyfiles = [f for f in listdir(directorImaginiOutput) if isfile(join(directorImaginiOutput, f))]\n",
        "    for fisier in onlyfiles:\n",
        "        if (fisier.endswith(\"jpg\") or fisier.endswith(\"png\") ) and \"aux\" not in fisier:\n",
        "            fisier = resizePoza(directorImaginiOutput,fisier,dimensiuneOut)\n",
        "            prelucreazaImagineOutput(fisier)\n",
        "            \n",
        "    intrare = []\n",
        "    iesire = []\n",
        "    for valori in dictionarImagini.values():\n",
        "        if(not isinstance(valori[0],int)) and (not isinstance(valori[1], int)):\n",
        "            intrare.append(valori[0])\n",
        "            iesire.append(valori[1])\n",
        "    intrare = numpy.array(intrare)\n",
        "    iesire =numpy.array(iesire)\n",
        "    print(len(intrare), len(iesire))\n",
        "    return intrare,iesire\n",
        "\n",
        "\n",
        "'''Retea\n",
        "Created on Apr 24, 2019\n",
        "\n",
        "@author: PITA\n",
        "'''\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Input,Flatten,Reshape,Dropout,BatchNormalization,Conv2DTranspose,UpSampling2D,concatenate\n",
        "from keras import optimizers, losses\n",
        "from keras import  regularizers\n",
        "from keras.regularizers import l2\n",
        "import keras.metrics\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "dimensiune = (256,256)\n",
        "\n",
        "def carenteTotale(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    a1 = K.sign(y_pred)\n",
        "    a2 = K.equal(y_true,K.sign(y_pred))\n",
        "    a3 = K.cast(K.equal(y_true,K.sign(y_pred)),tf.int16)\n",
        "    a4 = K.sum(K.cast(K.equal(y_true,K.sign(y_pred)),tf.int16))\n",
        "    K.print_tensor(y_pred)\n",
        "    return K.sum(K.cast(K.equal(y_true,K.sign(y_pred)),tf.int16))\n",
        "    \"\"\"\n",
        "    return K.sum(K.cast(K.equal(y_true, K.sign(y_pred)),K.floatx()))\n",
        "\n",
        "\n",
        "def pusaCarieSiNuE(y_true, y_pred):\n",
        "    aux1 = K.not_equal(y_true,K.sign(y_pred))\n",
        "    return K.sum(K.cast(K.equal(aux1,K.cast(K.sign(y_pred),tf.bool)),K.floatx()))\n",
        "    \n",
        "\n",
        "def trebeCarieSiNaPus(y_true, y_pred):\n",
        "    return carenteTotale(y_true, y_pred) + pusaCarieSiNuE(y_true, y_pred)\n",
        "    '''\n",
        "aux1 = K.not_equal(y_true,K.sign(y_pred))\n",
        "aux2 =  K.not_equal(K.ones(K.shape(y_pred)),K.sign(y_pred))\n",
        "return K.sum(K.cast(K.equal(aux1,aux2),tf.int16))\n",
        "'''\n",
        "def getModel():\n",
        "    global model\n",
        "    return model\n",
        "\n",
        "\n",
        "from keras.optimizers import *\n",
        "x=16 \n",
        "\n",
        "inputs = Input((dimensiune[0], dimensiune[1], 1))\n",
        "conv1 = Conv2D(x, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "conv1 = Conv2D(x, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = Conv2D(x*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "conv2 = Conv2D(x*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = Conv2D(x*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "conv3 = Conv2D(x*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "conv4 = Conv2D(x*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "conv4 = Conv2D(x*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "drop4 = Dropout(0.5)(conv4)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "conv5 = Conv2D(x*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "conv5 = Conv2D(x*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "up6 = Conv2D(x*8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "merge6 = concatenate([drop4,up6], axis = 3)\n",
        "conv6 = Conv2D(x*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "conv6 = Conv2D(x*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "up7 = Conv2D(x*4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "merge7 = concatenate([conv3,up7], axis = 3)\n",
        "conv7 = Conv2D(x*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "conv7 = Conv2D(x*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "up8 = Conv2D(x*2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "merge8 = concatenate([conv2,up8], axis = 3)\n",
        "conv8 = Conv2D(x*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "conv8 = Conv2D(x*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "up9 = Conv2D(x, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "merge9 = concatenate([conv1,up9], axis = 3)\n",
        "conv9 = Conv2D(x, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "conv9 = Conv2D(x, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "conv9 = Conv2D(8, 3,activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "conv9 = Conv2D(4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "conv9 = Conv2D(1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "\n",
        "conv9 = Flatten()(conv9)\n",
        "conv9 = Dense(1024,activation='relu')(conv9)\n",
        "conv9 = Dropout(0.5)(conv9)\n",
        "conv9 = Dense(1024,activation='relu')(conv9)\n",
        "conv9 = Dropout(0.5)(conv9)\n",
        "conv9 = Dense(1024,activation='relu')(conv9)\n",
        "conv9 = Dropout(0.5)(conv9)\n",
        "conv9 = Dense(65536,activation='sigmoid')(conv9)\n",
        "conv9 = Reshape((256,256))(conv9)\n",
        "\n",
        "# conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "# conv10 = Conv2D(1, 1, activation = 'elu',name=\"myOutputLayer\")(conv9)\n",
        "\n",
        "model = Model(input = inputs, output = conv9)\n",
        "\n",
        "sgd = optimizers.SGD(nesterov=True)\n",
        "model.compile(optimizer = Adam(), loss = keras.losses.categorical_crossentropy, metrics = [carenteTotale,pusaCarieSiNuE,trebeCarieSiNaPus])\n",
        "#model.compile(optimizer =sgd, loss = keras.losses.categorical_crossentropy, metrics = [carenteTotale,pusaCarieSiNuE,trebeCarieSiNaPus])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "'''Antrenament\n",
        "Created on May 2, 2019\n",
        "\n",
        "@author: narci\n",
        "'''\n",
        "import imutils\n",
        "import numpy\n",
        "print(imutils.__version__)\n",
        "#from Package.GetInput import mainInput\n",
        "#from Package import Retea\n",
        "#from Crypto.Random.random import shuffle\n",
        "import tensorflow as tf\n",
        "#from Package.MainScript import analizeazaPoza\n",
        "from keras.models import model_from_json\n",
        "\n",
        "def mainAntrenament() :\n",
        "    #session = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "    intrare, iesire  = mainInput()\n",
        "    #intrare = numpy.tile(intrare,10)\n",
        "    #iesire = numpy.tile(iesire, 10)\n",
        "    model = getModel()\n",
        "    \n",
        "    model.fit (intrare,iesire,epochs=10,batch_size=10,shuffle=True,validation_split=0.1)\n",
        "    salveazaModel(model)\n",
        "\n",
        "#folder = r'C:\\Users\\PITA\\git\\licenta2019\\Radiografii_DB'\n",
        "def  deleteAuxFiles(folder):\n",
        "    import os, shutil\n",
        "    for the_file in os.listdir(folder):\n",
        "        file_path = os.path.join(folder, the_file)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                if \"aux\" in file_path:\n",
        "                    os.unlink(file_path)\n",
        "            #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    print(\"Done\")\n",
        "    \n",
        "   \n",
        "   \n",
        "def salveazaModel(model):     \n",
        "        # serialize model to JSON\n",
        "        model_json = model.to_json()\n",
        "        with open(\"model3.json\", \"w\") as json_file:\n",
        "            json_file.write(model_json)\n",
        "        # serialize weights to HDF5\n",
        "        model.save_weights(\"/content/drive/My Drive/Colab Notebooks/licenta2019/model3.h5\")\n",
        "        print(\"Saved model to disk\")\n",
        " \n",
        "def incarcaModel():\n",
        "    # load json and create model\n",
        "    json_file = open('model.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    loaded_model.load_weights(\"model.h5\")\n",
        "    print(\"Loaded model from disk\")\n",
        "    return loaded_model\n",
        "    \n",
        "\n",
        "mainAntrenament()\n",
        "#analizeazaPoza(r\"/content/drive/My Drive/Colab Notebooks/licenta2019/Radiografii_DB/PHOTO-2019-04-20-15-56-23.jpg\")\n",
        "#deleteAuxFiles(\"/content/drive/My Drive/Colab Notebooks/licenta2019/Radiografii_DB\") \n",
        "#deleteAuxFiles(\"/content/drive/My Drive/Colab Notebooks/licenta2019/Radiografii_DB_Output\") \n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5564c21a275a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m \u001b[0mmainAntrenament\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;31m#analizeazaPoza(r\"/content/drive/My Drive/Colab Notebooks/licenta2019/Radiografii_DB/PHOTO-2019-04-20-15-56-23.jpg\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;31m#deleteAuxFiles(\"/content/drive/My Drive/Colab Notebooks/licenta2019/Radiografii_DB\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-5564c21a275a>\u001b[0m in \u001b[0;36mmainAntrenament\u001b[0;34m()\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mintrare\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miesire\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0msalveazaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}